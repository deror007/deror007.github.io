<!-- A W3 schools template -->
<!DOCTYPE html>
<html>
<head>
<title>Russell de Roeper</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" type="text/css" href="portfolio_styles.css">
<style>
body, h1,h2,h3,h4,h5,h6 {font-family: "Montserrat", sans-serif}
.w3-row-padding img {margin-bottom: 12px}
/* Set the width of the sidebar to 120px */
.w3-sidebar {width: 120px;background: #222;}
/* Add a left margin to the "page content" that matches the width of the sidebar (120px) */
#main {margin-left: 120px}
/* Remove margins from "page content" on small screens */
@media only screen and (max-width: 600px) {#main {margin-left: 0}}
</style>
</head>
<body class="w3-black">

<!-- Icon Bar (Sidebar - hidden on small screens) -->
<nav class="w3-sidebar w3-bar-block w3-small w3-hide-small w3-center">
  <!-- NOTE: Potential Light and dark mode here.-->
  <img src="https://media.githubusercontent.com/media/deror007/deror007.github.io/main/imgs/Sig_Icon.png" alt="Signature Icon" style="width: 120px; height: 120px;">
  <a href="#" class="w3-bar-item w3-button w3-padding-large w3-black">
    <i class="fa fa-home w3-xxlarge"></i>
    <p>HOME</p>
  </a>
  <a href="#about" class="w3-bar-item w3-button w3-padding-large w3-hover-black">
    <i class="fa fa-user w3-xxlarge"></i>
    <p>SUMMARY</p>
  </a>
  <a href="#portfolio" class="w3-bar-item w3-button w3-padding-large w3-hover-black">
    <i class="fa fa-eye w3-xxlarge"></i>
    <p>PORTFOLIO</p>
  </a>
  <a href="#contact" class="w3-bar-item w3-button w3-padding-large w3-hover-black">
    <i class="fa fa-envelope w3-xxlarge"></i>
    <p>CONTACT</p>
  </a>
</nav>

<!-- Navbar on small screens (Hidden on medium and large screens) -->
<div class="w3-top w3-hide-large w3-hide-medium" id="myNavbar">
  <div class="w3-bar w3-black w3-opacity w3-hover-opacity-off w3-center w3-small">
    <a href="#" class="w3-bar-item w3-button" style="width:25% !important">HOME</a>
    <a href="#about" class="w3-bar-item w3-button" style="width:25% !important">SUMMARY</a>
    <a href="#portfolio" class="w3-bar-item w3-button" style="width:25% !important">PORTFOLIO</a>
    <a href="#contact" class="w3-bar-item w3-button" style="width:25% !important">CONTACT</a>
  </div>
</div>

<!-- Page Content -->
<div class="w3-padding-large" id="main">
  <!-- Header/Home -->
  <header class="w3-container w3-padding-32 w3-center w3-black" id="home">
    <!-- <h1 class="w3-jumbo"><span class="w3-hide-small">Hi, I'm</span> Russell de Roeper.</h1> -->
    <h1 class="w3-jumbo" id="typewriter"><span></span></h1>

    <p>UCL MSc Cognitive and Decision Sciences Student and Part-Time Data Scientist</p>
    <!-- <img src="imgs/russell_img.jpg" alt="me" class="w3-image" width="756" height="975"> -->
    <div class = "image-center">
      <img src="https://media.githubusercontent.com/media/deror007/deror007.github.io/main/imgs/russell_img.jpg" alt="me" width="378" height="488" class="center-main-image">
    </div>
  </header>

  <!-- About Section -->
  <div class="w3-content w3-justify w3-text-grey " id="about">
 
    <h2 class="w3-text-light-grey">Summary</h2>
    <hr style="width:200px" class="w3-opacity">
    <p>I am a recent Computer Science and AI graduate from Loughborough University and a former software developer at Oscore ltd. I have always been fascinated with thinking machines and the human mind, this fascination has led me to become a MSc Cognitive and Decision Science student at UCL. I am looking to apply my studies to help build human-inspired machine learning models. Alongside my MSc degree, I am working part-time as a data scientist with Head of Data Ltd. In the future I want to continue exploring my research interests further, and hopefully apply this to real-world problems.</p>
    </p>

    <!-- <button class="w3-button w3-light-grey w3-padding-large w3-section">
      <i class="fa fa-download"></i> Download Resume
    </button> --> 
    <a href="https://drive.google.com/file/d/1BlrAIoyL4dlbYJuZbQ8S3lX4nHoYUvUj/view?usp=sharing" target="_blank">
      <button class="w3-button w3-light-grey w3-padding-large w3-section">
        <i class="fa fa-download"></i> Download Resume
      </button>
    </a>

        
  <!-- End About Section -->
  </div>
  
  <!-- Portfolio Section -->
  <div class="w3-padding-64 w3-content" id="portfolio">
  
    <h2 class="w3-text-light-grey">Coding Projects</h2>
    <hr style="width:200px" class="w3-opacity">

    <!-- Grid for portfolio collapsibles -->
    <div class="w3-row-padding" style="margin:0 -16px">
      
      <button type="button" class="collapsible ">Point Cloud Optimiser using a Genetic Algorithm</button>
      <div class="collapsibleContent">
        <div class="flex-container">
          <img src="https://media.githubusercontent.com/media/deror007/deror007.github.io/main/imgs/zed_robot_camera.jpg" alt="Robot with Zed Camera" class="collapsibleImage" style="width: 257px; height: 347px;">
          <p>During my summer internship with Loughborough University's Intelligent Automation Centre <a href="https://www.lboro.ac.uk/research/intelligent-automation/" target="_blank">(IAC)</a>, I was working on a method to optimise the Zed 2 Stereo Camera.<br><br> This device uses 2 cameras to produce point clouds. Point Clouds are 3D data structures that measure depth for each pixel in an image, this captures information of a 3D scene. The problem is that the quality of these point clouds generated by Zed 2 Camera's can be affected by the environment's lighting. The Zed 2 comes with many parameters that can be tuned to minimise this problem, but finding the optimal setting is difficult due to the huge number of combinations. <br><br> To minimise this problem, colleagues at the research centre and I spent the summer developing a genetic algorithm to search the space of possible settings that produce the best point clouds. Later on, I was able to represent Loughborough University by giving an oral presentation at the 2022 3D Metrology Conference in Aachen, Germany. Here is a <a href="https://www.3dmc.events/modules/static/archive/media/files/2022/Russell%20de%20Roeper%20-%20An%20Automated%20Approach%20To%20Evaluate.pdf" target="_blank">link</a> to the presentation that I gave at the conference.</p>
        </div>
      </div>
      
      <button type="button" class="collapsible">Variational Autoencoder Studies using Pytorch</button>
      <div class="collapsibleContent">
        <p>I have been exploring Generative AI through the book "Generative Deep Learning: Teaching Machines to Paint, Write, Compose, and Play by David Foster". Throughout the book elements of Variational Autoencoders (VAE's), have been crucial to this fields development through the concepts of encoders, decoders and latent spaces. What caught my eye is its use in the 2018 paper World Model's where an RL agent learns to recreate the pixel observation of a game. Then the agent uses these small reconstructions to predict future game observations, thus creating a model of the game environment. Due to the VAE's fast and good quality sampling from it's learned latent space, the agent can simulate the environment like as if it was dreaming the environment without using the game's actual observation. This simulated environment can only work after being trained on the environment, in order to learn the design of the observations. This motivated my studies into learning and implementing the VAE.</p>
        <img src="https://media.githubusercontent.com/media/deror007/deror007.github.io/main/imgs/improve_VAE%2064%20z%20vector%20recon.png" class="collapsibleImage">
        <figcaption>64-Dimensional Latent Vector Reconstruction</figcaption>
        <br><br>
        <img src="https://media.githubusercontent.com/media/deror007/deror007.github.io/main/imgs/improve_VAE%20384%20z%20vector%20recon.png" class="collapsibleImage">
        <figcaption>384-Dimensional Latent Vector Reconstruction</figcaption>
        <p>Using Pytorch, I have recreated the 2018 World Model's VAE architecture and applied it to the Cifar10 dataset. The images show the original and corresponding reconstructions. There are a few takeaways from these images. The first is that when the dimension of the latent vector increases, the quality of the reconstruction also increases as more detail can be stored in a larger vector for decoding. The other note is that the reconstructions are blurry. There are a few reasons for this, but the main reason is that VAE's focuses on structuring the latent space for better generative sampling rather than recreating precise reconstructions. I am currently looking to improve this model by adjusting the model's loss to produce better quality results.</p>
      </div>
      
      <button type="button" class="collapsible">2-Player Bullet Dodger Arcade Game</button>
      <div class="collapsibleContent">
        <div class="flex-container">
          <img src="https://media.githubusercontent.com/media/deror007/deror007.github.io/main/imgs/Bullet%20Dodger%20example.jpg"  class="collapsibleImage" style="width: 420px; height: 420px;">
          <p>I really enjoyed working on this side-project. It is a 2-player arcade game where the objective for the red rectangle player is to shoot the blue player by moving with the "left","right" arrow keys and shoot projectiles with the "a,s,d,f" keys. The blue player uses the mouse to dodge and evade the projectiles, and the score increases for every second the blue player survives. In this case I survived for only 6 seconds ðŸ˜….<br><br> I wanted to create this game in order to program simple physics for a potential Reinforcement Learning environment. The "a" key is a green bullet that moves straight at a constant speed. The "s" key is the shotgun key that shoots 3 yellow projectiles at 3 angles. The "d" key is the Tomahawk key that bounces a pink projectile off the closest side wall. Lastly, the "f" key is the grenade key, that shoots a white projectile that can bounce of objects and explodes after 5 seconds. This projectile particularly slows down as it moves to simulate wind or a rolling grenade when thrown. I have used PyGame to produce this. <br><br>Originally this game was meant to be an RL environment for the World Models recreation for my VAE. I created a dataset of game observations by using basic automated agents to simulate game data. However, VAE reconstructions of this particular environment is difficult as the VAE hits a local minima by recreating the black background with faint red and blue colours, most likely due to the blurrying effect of VAE's. These are not useful observations for a pixel exact game like this, so I repurposed the environment as a good-old arcade game.</p> 
        </div>
      </div>
      
      <button type="button" class="collapsible">Image to Artwork Recommender</button>
      <div class="collapsibleContent">
        <div class="flex-container">
          <img src="https://media.githubusercontent.com/media/deror007/deror007.github.io/main/imgs/image%20to%20art%20Gallery%20recommender.jpg" class="collapsibleImage" style="width: 520px; height: 520px;">
          <p>This project was built during my time at <a href="https://oscore.io/" target="_blank">Oscore</a> ltd. for the client <a href="https://signetcontemporaryart.com/" target="_blank">Signet Contemporary Art</a> (a london-based art gallery). The reference image includes their artworks on the output section of the program. The client wanted to have new ways to browse their art gallery, so with some brainstorming with other developers we created an artwork recommender. When the program is given an image, a particular artstyle and the total number of suggestions as input; the program outputs several similar artworks available from the art gallery. This way potential customers with an idea of what they want can more efficiently search the website for artworks.<br><br> By using a pretrained convolutional neural network that is trained on the ImageNet 1000 dataset. This neural network would output 1000 numbers representing how likely an image is to be one of the 1000 classes of the dataset. With this in mind, similar images will have similar results in the output of the network, and less similar images will have less similar results in the output of the model. So for this progam we have generated and saved a collection of outputs from the art gallery, were each image results in a vector (the output) of 1000 numbers between 0-1. Then using this set of vectors whenever an input image is given, the program runs the CNN to encode it into a vector like before and measures the distance between this input vector with the other vectors in our set. The most similar images will have the smallest distances, and we output the top-n artworks with the smallest results.<br><br> The reference image shows an example of this process were the output returns 5 images and we can suggest artwork over all genres in the gallery. Apparently, I look like Sean Connery's James Bond ðŸ˜Ž. This program only uses a small subset of the art gallery where we have taken 8 images per art genre. To improve the output of recommendations, a person can increase the image database and corresponding set of vectors. You can play with it <a href="https://huggingface.co/spaces/Deror/image-to-artwork_recommendation" target="_blank">here</a>.</p> 
        </div>
      </div>

      <button type="button" class="collapsible">ChatGPT Ticket Helper with Azure DevOps Webhook</button>
      <div class="collapsibleContent">
        <div class="flex-container">
          <p>This is another project I worked on during my time at <a href="https://oscore.io/" target="_blank">Oscore</a> ltd. With the huge interest of using Large Language Models as an assistive tool in programming, Oscore wanted an internal tool that automatically writes messages and potential solutions for work items found in Azure DevOps ticketing system. This would help developers in completing tickets faster, by already having ideas be generated to solve the problem and thus increasing productivity internally.<br><br> In order to do this a webhook is triggered whenever a ticket is made on Azure DevOps which calls a Flask API to generate the ChatGPT responses. To get the responses we provide the LLM details of the ticket using OpenAI's Assistant API, and ask for potential solutions for this ticket. This all happens in a separate thread within the triggered flask api call. When the responses are created, they are passed to Azure DevOps REST API, and the responses are displayed in markdown for improved visuals within that ticket's comment section.</p>
        </div>
      </div>
      
      <button type="button" class="collapsible">BSc Final Year Project: A Neuro-Symbolic Reinforcement Learning approach with the Logic Tensor Network.</button>
      <div class="collapsibleContent">
        <div class="image-center">
          <img src="https://media.githubusercontent.com/media/deror007/deror007.github.io/main/imgs/LTN%20%2B%20DDQN%20Overview.jpg" class="collapsibleImage center-main-image" style="width: 520px; height: 520px; transform: rotate(-90deg);">
        </div>
          <p>This was my final year project at Loughborough University under the supervision of Dr. Andrea Soltoggio. Neuro-Symbolic models focus on combining traditional Symbolic AI with neural network models. An example of a neuro-symbolic model is the Logic Tensor Network (LTN) which uses formal logic with neural networks to embed knowledge into the model. With this, I explored how this can be used to make an interpretable reinforcement learning agent within the Minihack RL environment. By taking advantage of Minihack's ascii-based observations, I was able to provide the agent information about the game environment and customise a loss function based on this. Using the LTN's formal logic language called Real Logic, I was able to express this information in its knowledge base. The LTN calculate loss by measuring how it's output satisfies this knowledge base. The better that it satisfies the knowledge base, the lower the loss. It follows the original Deep Q-Network paper by using epsilon-greedy strategy to either explore the state space or exploit it's best known actions by utilising its neural network to compute Q-values.<br><br> For this project I was happily awarded 84%. I have attached my paper <a href="https://drive.google.com/file/d/1FmMmpiXoLWELcIfHDG2rpANI3sxNqOdn/view?usp=sharing" target="_blank">here</a>.</p>
      </div>
      
   
    <!-- End portfolio collapsibles -->
    </div>
  <!-- End Portfolio Section -->

    <script src="scripts.js"></script>

  </div>
  

  <!-- Contact Section -->
  <div class=" w3-content w3-text-grey" id="contact">
    <h2 class="w3-text-light-grey">Contact Me</h2>
    <hr style="width:200px" class="w3-opacity">

    <div class="w3-section">
      <p>Let's get in touch. Send me a message.</p>
      <p><i class="fa fa-map-marker fa-fw w3-text-white w3-xxlarge w3-margin-right"></i> London, UK</p>
      <!-- <p><i class="fa fa-envelope fa-fw w3-text-white w3-xxlarge w3-margin-right"> </i> Email: russell.roeper@gmail.com</p> -->
      <p>
        <i class="fa fa-envelope fa-fw w3-text-white w3-xxlarge w3-margin-right"></i> 
        Email: <span id="email"></span>
      </p>
      
      <p id="linkedin">
        <a href="https://www.linkedin.com/in/russellderoeper/" target="_blank">
          <i class="fa fa-linkedin fa-fw w3-text-white w3-xxlarge w3-margin-right w3-hover-opacity"></i>
        </a>
      </p>
      <p id = "github">
        <a href="https://github.com/deror007" target="_blank">
          <i class="fa fa-github fa-fw w3-text-white w3-xxlarge w3-margin-right w3-hover-opacity"></i>
        </a>
      </p>
    </div><br>
    

  </div>
  
</div>

</body>
</html>
